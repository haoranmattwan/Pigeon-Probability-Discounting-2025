{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6f465c",
   "metadata": {},
   "source": [
    "# Discounting of Probabilistic Food Reinforcement by Pigeons\n",
    "\n",
    "This notebook provides a complete Python-based replication of the analyses from the publication:\n",
    "\n",
    "> Oliveira, L., Green, L., Myerson, J., & Wan, H. (2025). Discounting of probabilistic food reinforcement by pigeons. *Journal of the Experimental Analysis of Behavior, 124*(1). https://doi.org/10.1002/jeab.70042\n",
    "\n",
    "The original R analysis (`brms`) is translated into a Python workflow using `pandas`, `pymc`, `arviz`, and `matplotlib`. The analysis uses Bayesian nonlinear multilevel models to fit a hyperboloid discounting function to pigeons' choices.\n",
    "\n",
    "The data for this study are publicly available on the Open Science Framework at: <https://osf.io/scwg3/>.\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "1.  **Setup**: Imports all necessary Python libraries and defines a custom plotting theme.\n",
    "2.  **Data Processing**: Loads the raw data from both experiments, cleans and transforms it, and calculates the Area under the Curve (AuC) for each subject and condition.\n",
    "3.  **Experiment 1**:\n",
    "    * Fits a Bayesian multilevel hyperboloid model to the \"certain vs. probabilistic\" choice data.\n",
    "    * Visualizes the model fits (Figure 1 replication).\n",
    "    * Calculates Bayesian $R^2$ and replicates the AuC analysis (Table 1 & Figure 2 replication).\n",
    "4.  **Experiment 2**:\n",
    "    * Fits the generalized hyperboloid model to the \"probabilistic vs. probabilistic\" choice data for all 6 conditions.\n",
    "    * Visualizes the model fits (Figures 3-5 replication).\n",
    "    * Calculates Bayesian $R^2$ and replicates the AuC analysis (Table 2 replication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5617ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Environment Setup ---\n",
    "# This cell installs all the required Python packages.\n",
    "# It is commented out by default. Uncomment and run this cell if the packages \n",
    "# are not yet installed in your environment.\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas numpy pymc arviz matplotlib seaborn scikit-learn openpyxl statsmodels jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f990c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Imports, Settings, and Helper Functions ---\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# --- Modeling ---\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.metrics import auc as calculate_trapezoid_auc\n",
    "\n",
    "# --- Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Global Settings ---\n",
    "# Suppress warnings for a cleaner notebook output\n",
    "warnings.filterwarnings('ignore')\n",
    "# Standardize float display format\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# --- Custom Plotting Theme ---\n",
    "def style_plot(ax: plt.Axes, title: str = \"\"):\n",
    "    \"\"\"\n",
    "    Applies a consistent, publication-quality theme to a Matplotlib axes object.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): The axes object to style.\n",
    "        title (str): The title for the plot.\n",
    "    \"\"\"\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10, direction='out')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(1)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(False)\n",
    "    if ax.get_legend():\n",
    "        ax.get_legend().set_frame_on(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf635764",
   "metadata": {},
   "source": [
    "## Data Loading & Processing\n",
    "\n",
    "This section loads the raw data for both experiments from the OSF repository, processes them into a single, analysis-ready DataFrame, and calculates the Area under the Curve (AuC) for each subject and condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Loading and Processing ---\n",
    "\n",
    "# --- Load OSF Data ---\n",
    "raw_data_exp1 = pd.read_csv(\"PigeonPD_Exp1.csv\", dtype={'Probability': 'str'})\n",
    "raw_data_exp2 = pd.read_csv(\"PigeonPD_Exp2.csv\", dtype={'Multiplier': 'str'})\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# --- Process Experiment 1 Data ---\n",
    "# 'Probability' is now guaranteed to be a string, so .str will work\n",
    "processed_data_exp1 = raw_data_exp1.assign(\n",
    "    Experiment=1,\n",
    "    Rep=lambda x: x['Probability'].str.contains(\"R\").astype(int),\n",
    "    Prob_Lg=lambda x: x['Probability'].str.replace(\"R\", \"\").astype(float) / 100,\n",
    "    OAs=lambda x: (1 - x['Prob_Lg']) / x['Prob_Lg'],\n",
    "    RSV=lambda x: x['SV'] / x['Amount'],\n",
    "    Multiplier=1.0,\n",
    "    OAs_Sm=0\n",
    ").filter(items=['Subject', 'Experiment', 'Multiplier', 'Amount', 'Rep', 'OAs', 'RSV', 'OAs_Sm', 'Prob_Lg'])\n",
    "\n",
    "# --- Process Experiment 2 Data ---\n",
    "# 'Multiplier' is now guaranteed to be a string, so .str will work\n",
    "processed_data_exp2 = raw_data_exp2.assign(\n",
    "    Experiment=2,\n",
    "    Rep=lambda x: x['Multiplier'].str.contains(\"R\").astype(int),\n",
    "    Multiplier=lambda x: x['Multiplier'].str.replace(\"R\", \"\").astype(float),\n",
    "    Prob_Lg=lambda x: x['Probability_Lg'] / 100,\n",
    "    Prob_Sm=lambda x: x['Probability_Sm'] / 100,\n",
    "    OAs=lambda x: (1 - x['Prob_Lg']) / x['Prob_Lg'],\n",
    "    OAs_Sm=lambda x: (1 - x['Prob_Sm']) / x['Prob_Sm'],\n",
    "    RSV=lambda x: x['SV'] / x['Amount']\n",
    ").filter(items=['Subject', 'Experiment', 'Multiplier', 'Amount', 'Rep', 'OAs', 'RSV', 'OAs_Sm', 'Prob_Lg'])\n",
    "\n",
    "# --- Combine Data & Create Mean Subject ---\n",
    "combined_data = pd.concat([processed_data_exp1, processed_data_exp2])\n",
    "\n",
    "mean_data = combined_data[combined_data['Rep'] == 0].groupby(\n",
    "    ['Experiment', 'Amount', 'Multiplier', 'OAs', 'Prob_Lg', 'OAs_Sm'], as_index=False\n",
    ")['RSV'].mean().assign(Subject=\"Mean\", Rep=0)\n",
    "\n",
    "combined_data = pd.concat([combined_data, mean_data])\n",
    "\n",
    "# Set Subject as categorical with 'Mean' last\n",
    "subject_levels = [\"P41\",\"P42\",\"P43\",\"P44\",\"P45\",\"P46\",\"P47\",\"P48\",\"Mean\"]\n",
    "combined_data['Subject'] = pd.Categorical(\n",
    "    combined_data['Subject'], categories=subject_levels, ordered=True\n",
    ")\n",
    "# Clip RSV for Beta regression, which requires the outcome to be in the open interval (0, 1)\n",
    "combined_data['RSV'] = np.clip(combined_data['RSV'], 1e-6, 1 - 1e-6)\n",
    "\n",
    "# --- Create AuC Dataframe ---\n",
    "def calculate_auc_group(df: pd.DataFrame) -> float:\n",
    "    \"\"\"Helper function to calculate AuC for a group.\"\"\"\n",
    "    df = df.sort_values('OAs')\n",
    "    # Normalize OAs to a 0-1 scale for AuC calculation\n",
    "    # Add 0,0 point to anchor the curve if min OAs is not 0\n",
    "    oas_vals = df['OAs']\n",
    "    rsv_vals = df['RSV']\n",
    "    if oas_vals.min() > 0:\n",
    "        oas_vals = pd.concat([pd.Series([0]), oas_vals])\n",
    "        rsv_vals = pd.concat([pd.Series([1]), rsv_vals]) # Assuming RSV=1 at OAs=0\n",
    "        \n",
    "    norm_oas = oas_vals / oas_vals.max()\n",
    "    return calculate_trapezoid_auc(norm_oas, rsv_vals)\n",
    "\n",
    "auc_data = combined_data[combined_data['Rep'] == 0].groupby(\n",
    "    ['Subject', 'Experiment', 'Multiplier', 'Amount']\n",
    ").apply(calculate_auc_group).reset_index(name='AuC')\n",
    "\n",
    "print(f\"Data processing complete. {len(combined_data)} total rows loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470076b",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Certain vs. Probabilistic Rewards\n",
    "\n",
    "In Experiment 1, pigeons chose between a smaller, certain reinforcer (Odds Against = 0) and a larger, probabilistic reinforcer. The following section fits the hyperboloid discounting model (Equation 1) to the data for each amount (16 and 32 pellets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 1: Bayesian Model Fitting ---\n",
    "\n",
    "def fit_model_exp1(model_data: pd.DataFrame) -> (az.InferenceData, pm.Model):\n",
    "    \"\"\"\n",
    "    Fits the Bayesian hyperboloid model for Experiment 1.\n",
    "    RSV = 1 / (1 + h * OAs)^s\n",
    "    \"\"\"\n",
    "    coords = {\"Subject\": model_data['Subject'].cat.categories}\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # --- Define Data ---\n",
    "        # Get integer codes for subject indices\n",
    "        subject_idx = pd.Categorical(model_data['Subject'], categories=coords[\"Subject\"]).codes\n",
    "        # Create mutable data containers for PyMC\n",
    "        oas_data = pm.Data(\"oas_data\", model_data['OAs'].values)\n",
    "        subject_idx_data = pm.Data(\"subject_idx_data\", subject_idx)\n",
    "        \n",
    "        # --- Priors ---\n",
    "        # Using 'h' for the rate param to match user's R code\n",
    "        h = pm.TruncatedNormal(\"h\", mu=1, sigma=10, lower=0, dims=\"Subject\")\n",
    "        s = pm.TruncatedNormal(\"s\", mu=1, sigma=10, lower=0, dims=\"Subject\")\n",
    "        # 'nu' is the precision parameter (phi in brms/paper)\n",
    "        nu = pm.HalfCauchy(\"nu\", beta=10, dims=\"Subject\")\n",
    "\n",
    "        # --- Model Definition (Equation 1) ---\n",
    "        mu = 1 / (1 + h[subject_idx_data] * oas_data)**s[subject_idx_data]\n",
    "        \n",
    "        # --- Likelihood ---\n",
    "        # Use Beta regression for proportional RSV data\n",
    "        pm.Beta(\"RSV\", mu=mu, nu=nu[subject_idx_data], observed=model_data['RSV'].values)\n",
    "        \n",
    "        # --- Sampling ---\n",
    "        idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, progressbar=False, target_accept=0.95)\n",
    "    return idata, model\n",
    "\n",
    "# --- Fit models for each amount ---\n",
    "print(\"Fitting Experiment 1 models...\")\n",
    "# 16-Pellet Model\n",
    "data_exp1_16p = combined_data[(combined_data.Experiment == 1) & (combined_data.Rep == 0) & (combined_data.Amount == 16)]\n",
    "idata_exp1_16, model_exp1_16 = fit_model_exp1(data_exp1_16p)\n",
    "\n",
    "# 32-Pellet Model\n",
    "data_exp1_32p = combined_data[(combined_data.Experiment == 1) & (combined_data.Rep == 0) & (combined_data.Amount == 32)]\n",
    "idata_exp1_32, model_exp1_32 = fit_model_exp1(data_exp1_32p)\n",
    "\n",
    "print(\"Experiment 1 model fitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 1: Plotting Results (Figure 1 Replication) ---\n",
    "\n",
    "def get_predictions_exp1(idata: az.InferenceData, amount_val: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates median posterior predictions for Experiment 1 models.\n",
    "    \"\"\"\n",
    "    # Extract posterior draws for parameters\n",
    "    post_h = az.extract(idata, var_names=[\"h\"])\n",
    "    post_s = az.extract(idata, var_names=[\"s\"])\n",
    "    \n",
    "    pred_df_list = []\n",
    "    # Iterate through each subject in the model\n",
    "    for subj in idata.posterior.Subject.values:\n",
    "        # Create a smooth grid of OAs values for plotting\n",
    "        oas_grid = np.linspace(0, 10, 100)\n",
    "        \n",
    "        # Get the median parameter estimates for this subject\n",
    "        h_med = post_h.sel(Subject=subj).median().item()\n",
    "        s_med = post_s.sel(Subject=subj).median().item()\n",
    "        \n",
    "        # Calculate predicted RSV using the hyperboloid formula\n",
    "        pred_rsv = 1 / (1 + h_med * oas_grid)**s_med\n",
    "        \n",
    "        pred_df_list.append(pd.DataFrame({\n",
    "            'Subject': subj, 'OAs': oas_grid, '.epred': pred_rsv\n",
    "        }))\n",
    "    \n",
    "    # Combine predictions for all subjects\n",
    "    pred_df = pd.concat(pred_df_list)\n",
    "    pred_df['Amount'] = f\"{amount_val} Pellets\"\n",
    "    return pred_df\n",
    "\n",
    "# --- Generate prediction curves for both models ---\n",
    "pred_curves_exp1 = pd.concat([\n",
    "    get_predictions_exp1(idata_exp1_16, 16),\n",
    "    get_predictions_exp1(idata_exp1_32, 32)\n",
    "])\n",
    "pred_curves_exp1['Amount'] = pd.Categorical(pred_curves_exp1['Amount'], categories=[\"32 Pellets\", \"16 Pellets\"])\n",
    "\n",
    "\n",
    "# --- Create the FacetGrid Plot ---\n",
    "plot_data_exp1 = combined_data[(combined_data.Experiment == 1)].copy()\n",
    "plot_data_exp1['Amount'] = pd.Categorical(plot_data_exp1['Amount'].replace({16: \"16 Pellets\", 32: \"32 Pellets\"}),\n",
    "                                          categories=[\"32 Pellets\", \"16 Pellets\"])\n",
    "\n",
    "# Define colors and markers\n",
    "palette_fill = {\"16 Pellets\": \"#DD8452\", \"32 Pellets\": \"#4C72B0\"}\n",
    "palette_line = {\"16 Pellets\": \"#A65329\", \"32 Pellets\": \"#2E4A7F\"}\n",
    "markers = {\"16 Pellets\": \"v\", \"32 Pellets\": \"^\"}\n",
    "linestyles = {\"16 Pellets\": \"solid\", \"32 Pellets\": (0, (5, 5))} # 'solid' and 'dashed'\n",
    "\n",
    "# 1. Initialize the FacetGrid\n",
    "g = sns.FacetGrid(plot_data_exp1, col=\"Subject\", col_wrap=3, height=4, aspect=1)\n",
    "\n",
    "# 2. Map the scatterplot for the observed data (Rep == 0)\n",
    "g.map_dataframe(sns.scatterplot, x='OAs', y='RSV', hue='Amount', style='Amount', s=100,\n",
    "                data=plot_data_exp1[plot_data_exp1.Rep == 0],\n",
    "                palette=palette_fill, markers=markers,\n",
    "                hue_order=[\"32 Pellets\", \"16 Pellets\"], style_order=[\"32 Pellets\", \"16 Pellets\"])\n",
    "\n",
    "# 3. Map the scatterplot for the replication data (Rep == 1, open symbols)\n",
    "g.map_dataframe(sns.scatterplot, x='OAs', y='RSV', style='Amount', s=100,\n",
    "                data=plot_data_exp1[plot_data_exp1.Rep == 1],\n",
    "                marker='o', facecolors='none', edgecolors='black',\n",
    "                style_order=[\"32 Pellets\", \"16 Pellets\"], legend=False)\n",
    "\n",
    "# 4. Iterate through axes to overlay prediction lines\n",
    "for subject, ax in g.axes_dict.items():\n",
    "    line_data = pred_curves_exp1[pred_curves_exp1.Subject == subject]\n",
    "    sns.lineplot(\n",
    "        data=line_data,\n",
    "        x='OAs',\n",
    "        y='.epred',\n",
    "        hue='Amount',\n",
    "        style='Amount',\n",
    "        ax=ax,\n",
    "        palette=palette_line,\n",
    "        hue_order=[\"32 Pellets\", \"16 Pellets\"],\n",
    "        style_order=[\"32 Pellets\", \"16 Pellets\"],\n",
    "        legend=False  # Turn off legend for lines to avoid duplicates\n",
    "    )\n",
    "    style_plot(ax) # Apply custom theme\n",
    "\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.set_axis_labels(\"Odds Against\", \"Mean Relative Subjective Value\")\n",
    "g.add_legend(title=\"Amount\")\n",
    "g.set(ylim=(-0.05, 1.05), xlim=(-0.5, 10.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f049d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 1: Results and Amount Effect (Table 1 & Figure 2 Replication) ---\n",
    "\n",
    "def calculate_r2_exp1(model: pm.Model, idata: az.InferenceData, model_data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Calculates Bayesian R-squared for each subject in an Experiment 1 model.\"\"\"\n",
    "    with model:\n",
    "        # Set data to the full dataset for this model\n",
    "        pm.set_data({\n",
    "            \"oas_data\": model_data['OAs'].values,\n",
    "            \"subject_idx_data\": pd.Categorical(model_data['Subject'], categories=model.coords['Subject']).codes\n",
    "        })\n",
    "        # Generate ONE posterior predictive sample\n",
    "        post_pred = pm.sample_posterior_predictive(idata, var_names=[\"RSV\"], random_seed=42, progressbar=False)\n",
    "\n",
    "    # Calculate median prediction for each observation\n",
    "    epred = post_pred.posterior_predictive['RSV'].median(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "    # Add predictions to a copy of the dataframe\n",
    "    results_df = model_data.copy()\n",
    "    results_df['.epred'] = epred\n",
    "    results_df['residual'] = results_df['RSV'] - results_df['.epred']\n",
    "\n",
    "    # Calculate Sum of Squares Residual (ss_res) for each subject\n",
    "    ss_res = results_df.groupby('Subject', observed=True)['residual'].apply(lambda x: (x**2).sum())\n",
    "\n",
    "    # Calculate Sum of Squares Total (ss_tot) for each subject\n",
    "    def ss_total(x):\n",
    "        return ((x - x.mean())**2).sum()\n",
    "    ss_tot = results_df.groupby('Subject', observed=True)['RSV'].apply(ss_total)\n",
    "\n",
    "    # Calculate R2 for each subject\n",
    "    r2_series = 1 - (ss_res / ss_tot)\n",
    "    return r2_series\n",
    "\n",
    "def get_param_summary(idata: az.InferenceData, amount: int) -> pd.DataFrame:\n",
    "    \"\"\"Extracts parameter estimates (mean, sd) for each subject.\"\"\"\n",
    "    summary = az.summary(idata, var_names=['h', 's'], kind='stats')\n",
    "    summary['Subject'] = summary.index.str.split('[').str[1].str.replace(']', '')\n",
    "    summary['Parameter'] = summary.index.str.split('[').str[0]\n",
    "    summary['Amount'] = amount\n",
    "    return summary[['Subject', 'Amount', 'Parameter', 'mean', 'sd']]\n",
    "\n",
    "# --- Calculate and Display R-squared ---\n",
    "print(\"--- Experiment 1: Bayesian R-squared by Subject ---\")\n",
    "r2_16 = calculate_r2_exp1(model_exp1_16, idata_exp1_16, data_exp1_16p)\n",
    "r2_32 = calculate_r2_exp1(model_exp1_32, idata_exp1_32, data_exp1_32p)\n",
    "\n",
    "r2_table = pd.DataFrame({'R2_16p': r2_16, 'R2_32p': r2_32})\n",
    "print(r2_table)\n",
    "print(f\"\\nMedian R2 (16 Pellets): {r2_16.median():.3f}\")\n",
    "print(f\"Median R2 (32 Pellets): {r2_32.median():.3f}\")\n",
    "\n",
    "# --- Parameter Table (Replicates Table 1) ---\n",
    "params_summary_exp1 = pd.concat([get_param_summary(idata_exp1_16, 16), get_param_summary(idata_exp1_32, 32)])\n",
    "params_table_exp1 = params_summary_exp1.pivot(index=['Subject', 'Amount'], columns='Parameter', values=['mean', 'sd'])\n",
    "print(\"\\n--- Parameter Estimates (Replicates Table 1) ---\")\n",
    "print(params_table_exp1)\n",
    "\n",
    "# --- Amount Effect on AuC (GEE Model) ---\n",
    "print(\"\\n--- Amount Effect on AuC (GEE) ---\")\n",
    "auc_data_exp1 = auc_data[(auc_data.Experiment == 1) & (auc_data.Subject != 'Mean')].copy()\n",
    "auc_data_exp1['Amount_cat'] = auc_data_exp1['Amount'].astype('category')\n",
    "\n",
    "# Use Generalized Estimating Equations (GEE) to account for repeated measures (by Subject)\n",
    "# This is a Python equivalent to R's glmmTMB/lme4 for this type of test.\n",
    "# We use a Binomial family as AuC is bounded [0, 1] (similar to Beta regression)\n",
    "gee_model = smf.gee(\n",
    "    \"AuC ~ C(Amount_cat, Treatment(reference=16))\", \n",
    "    \"Subject\",\n",
    "    data=auc_data_exp1, \n",
    "    family=sm.families.Binomial()\n",
    ").fit()\n",
    "print(gee_model.summary())\n",
    "print(\"\\nNo significant effect of Amount on AuC was found (p > .05).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e644d",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 2: Two Probabilistic Rewards\n",
    "\n",
    "In Experiment 2, the probabilities of both options were reduced by a common multiplier (1.0, 0.75, or 0.25), creating choices where both outcomes were probabilistic. This section fits the generalized hyperboloid model (Equation 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 2: Bayesian Model Fitting ---\n",
    "\n",
    "def fit_model_exp2(model_data: pd.DataFrame) -> (az.InferenceData, pm.Model):\n",
    "    \"\"\"\n",
    "    Fits the Bayesian generalized hyperboloid model for Experiment 2.\n",
    "    RSV = ((1 + h * OAs_Sm)^s) / ((1 + h * OAs)^s)\n",
    "    \"\"\"\n",
    "    subjects_in_data = model_data['Subject'].cat.categories\n",
    "    coords = {\"Subject\": subjects_in_data}\n",
    "    \n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # --- Define Data ---\n",
    "        subject_idx = pd.Categorical(model_data['Subject'], categories=coords[\"Subject\"]).codes\n",
    "        # Create mutable data containers\n",
    "        oas_data = pm.Data(\"oas_data\", model_data['OAs'].values)\n",
    "        oas_sm_data = pm.Data(\"oas_sm_data\", model_data['OAs_Sm'].values)\n",
    "        subject_idx_data = pm.Data(\"subject_idx_data\", subject_idx)\n",
    "        \n",
    "        # --- Priors ---\n",
    "        h = pm.TruncatedNormal(\"h\", mu=1, sigma=10, lower=0, dims=\"Subject\")\n",
    "        s = pm.TruncatedNormal(\"s\", mu=1, sigma=10, lower=0, dims=\"Subject\")\n",
    "        nu = pm.HalfCauchy(\"nu\", beta=10, dims=\"Subject\")\n",
    "        \n",
    "        # --- Model Definition (Equation 2) ---\n",
    "        mu = ((1 + h[subject_idx_data] * oas_sm_data)**s[subject_idx_data]) / \\\n",
    "             ((1 + h[subject_idx_data] * oas_data)**s[subject_idx_data])\n",
    "        \n",
    "        # --- Likelihood ---\n",
    "        pm.Beta(\"RSV\", mu=mu, nu=nu[subject_idx_data], observed=model_data['RSV'].values)\n",
    "        \n",
    "        # --- Sampling ---\n",
    "        idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, progressbar=False, target_accept=0.95) \n",
    "    \n",
    "    return idata, model\n",
    "\n",
    "# --- Fit all 6 models for Experiment 2 ---\n",
    "filtered_data_exp2 = combined_data[(combined_data.Experiment == 2) & (combined_data.Rep == 0)].copy()\n",
    "filtered_data_exp2['Subject'] = filtered_data_exp2['Subject'].cat.remove_unused_categories()\n",
    "\n",
    "# Create dictionaries to store the fitted models and their inference data\n",
    "idata_exp2 = {}\n",
    "models_exp2 = {}\n",
    "\n",
    "for amt in [16, 32]:\n",
    "    for mult in [1.0, 0.75, 0.25]:\n",
    "        key = f\"amt{amt}_mult{int(mult*100)}\"\n",
    "        print(f\"Fitting {key}...\")\n",
    "        \n",
    "        # Filter data for this specific condition\n",
    "        data_subset = filtered_data_exp2[\n",
    "            (filtered_data_exp2.Amount == amt) & (filtered_data_exp2.Multiplier == mult)\n",
    "        ].copy()\n",
    "        data_subset['Subject'] = data_subset['Subject'].cat.remove_unused_categories()\n",
    "\n",
    "        # Fit the model and store both idata and the model object\n",
    "        idata_obj, model_obj = fit_model_exp2(data_subset)\n",
    "        idata_exp2[key] = idata_obj\n",
    "        models_exp2[key] = model_obj\n",
    "\n",
    "print(\"Experiment 2 model fitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe87b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 2: Plotting Results (Figures 3-5 Replication) ---\n",
    "\n",
    "def get_predictions_exp2(idata: az.InferenceData, amount_val: int, mult_val: float, model_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generates median predictions for Experiment 2 models.\"\"\"\n",
    "    post_h = az.extract(idata, var_names=[\"h\"])\n",
    "    post_s = az.extract(idata, var_names=[\"s\"])\n",
    "    \n",
    "    pred_df_list = []\n",
    "    subjects_in_model = idata.posterior.Subject.values\n",
    "    \n",
    "    for subj in subjects_in_model:\n",
    "        # Create a grid of OAs for prediction\n",
    "        oas_grid = np.linspace(\n",
    "            model_data['OAs'].min(), model_data['OAs'].max(), 100\n",
    "        )\n",
    "        # Get the single OAs_Sm value for this condition\n",
    "        oas_sm_val = model_data['OAs_Sm'].iloc[0]\n",
    "\n",
    "        # Get median parameter estimates\n",
    "        h_med = post_h.sel(Subject=subj).median().item()\n",
    "        s_med = post_s.sel(Subject=subj).median().item()\n",
    "        \n",
    "        # Calculate predicted RSV using the Exp 2 formula (Eq. 2)\n",
    "        pred_rsv = ((1 + h_med * oas_sm_val)**s_med) / ((1 + h_med * oas_grid)**s_med)\n",
    "        \n",
    "        pred_df_list.append(pd.DataFrame({\n",
    "            'Subject': subj, 'OAs': oas_grid, '.epred': pred_rsv\n",
    "        }))\n",
    "    \n",
    "    pred_df = pd.concat(pred_df_list)\n",
    "    pred_df['Amount'] = f\"{amount_val} Pellets\"\n",
    "    pred_df['Multiplier'] = mult_val\n",
    "    return pred_df\n",
    "\n",
    "# --- Generate predictions for all 6 models ---\n",
    "pred_curves_list_exp2 = []\n",
    "for (key, idata_obj) in idata_exp2.items():\n",
    "    amt = 16 if 'amt16' in key else 32\n",
    "    mult = 1.0 if 'mult100' in key else (0.75 if 'mult75' in key else 0.25)\n",
    "    data_subset = filtered_data_exp2[(filtered_data_exp2.Amount == amt) & (filtered_data_exp2.Multiplier == mult)]\n",
    "    pred_curves_list_exp2.append(get_predictions_exp2(idata_obj, amt, mult, data_subset))\n",
    "\n",
    "pred_curves_exp2 = pd.concat(pred_curves_list_exp2)\n",
    "\n",
    "# --- Prepare data for plotting ---\n",
    "# Calculate \"Relative Odds Against\" (Rel_OAs) for the x-axis\n",
    "# This normalizes the OAs across multiplier conditions\n",
    "def calculate_rel_oas(row):\n",
    "    prob = 1 / (row['OAs'] + 1)\n",
    "    rel_prob = prob / row['Multiplier']\n",
    "    return (1 - rel_prob) / rel_prob\n",
    "\n",
    "# Apply to observed data\n",
    "plot_data_exp2 = combined_data[combined_data.Experiment == 2].copy()\n",
    "plot_data_exp2['Rel_OAs'] = plot_data_exp2.apply(calculate_rel_oas, axis=1)\n",
    "plot_data_exp2['Amount'] = pd.Categorical(plot_data_exp2['Amount'].replace({16: \"16 Pellets\", 32: \"32 Pellets\"}))\n",
    "plot_data_exp2['Multiplier_Label'] = pd.Categorical(plot_data_exp2['Multiplier'].replace({1.0: \"Multiplier 1.0\", 0.75: \"Multiplier 0.75\", 0.25: \"Multiplier 0.25\"}))\n",
    "\n",
    "# Apply to prediction data\n",
    "pred_curves_exp2['Rel_OAs'] = pred_curves_exp2.apply(calculate_rel_oas, axis=1)\n",
    "pred_curves_exp2['Amount'] = pd.Categorical(pred_curves_exp2['Amount'])\n",
    "pred_curves_exp2['Multiplier_Label'] = pd.Categorical(pred_curves_exp2['Multiplier'].replace({1.0: \"Multiplier 1.0\", 0.75: \"Multiplier 0.75\", 0.25: \"Multiplier 0.25\"}))\n",
    "\n",
    "\n",
    "# --- Create the FacetGrid Plot ---\n",
    "g = sns.FacetGrid(plot_data_exp2, \n",
    "                  row=\"Subject\", col=\"Multiplier_Label\", \n",
    "                  height=2.5, aspect=1.5,\n",
    "                  sharex=True, sharey=True, \n",
    "                  row_order=subject_levels) # Use the defined subject order\n",
    "\n",
    "# Map the scatterplot of observed data\n",
    "g.map_dataframe(sns.scatterplot, x='Rel_OAs', y='RSV', hue='Amount', style='Amount', s=50,\n",
    "                palette=palette_fill, markers=markers,\n",
    "                hue_order=[\"32 Pellets\", \"16 Pellets\"])\n",
    "\n",
    "# Iterate over axes to overlay prediction lines\n",
    "for (row_val, col_val), ax in g.axes_dict.items():\n",
    "    line_data = pred_curves_exp2[(pred_curves_exp2.Subject == row_val) & (pred_curves_exp2.Multiplier_Label == col_val)]\n",
    "    sns.lineplot(\n",
    "        data=line_data,\n",
    "        x='Rel_OAs',\n",
    "        y='.epred',\n",
    "        hue='Amount',\n",
    "        style='Amount',\n",
    "        ax=ax,\n",
    "        palette=palette_line,\n",
    "        hue_order=[\"32 Pellets\", \"16 Pellets\"],\n",
    "        legend=False\n",
    "    )\n",
    "    style_plot(ax) # Apply custom theme\n",
    "    ax.set_xticks(range(0, 5, 1)) # Set x-ticks 0, 1, 2, 3, 4\n",
    "\n",
    "g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"Relative Odds Against\", \"Mean RSV\")\n",
    "g.add_legend(title=\"Amount\")\n",
    "g.set(ylim=(-0.05, 1.05), xlim=(-0.1, 4.1))\n",
    "g.fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b38369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 2: Results and Amount Effect (Table 2 Replication) ---\n",
    "\n",
    "def calculate_r2_exp2(model: pm.Model, idata: az.InferenceData, model_data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Calculates Bayesian R-squared for each subject in an Experiment 2 model.\"\"\"\n",
    "    with model:\n",
    "        # Set all required mutable data\n",
    "        pm.set_data({\n",
    "            \"oas_data\": model_data['OAs'].values,\n",
    "            \"oas_sm_data\": model_data['OAs_Sm'].values,\n",
    "            \"subject_idx_data\": pd.Categorical(model_data['Subject'], categories=model.coords['Subject']).codes\n",
    "        })\n",
    "        post_pred = pm.sample_posterior_predictive(idata, var_names=[\"RSV\"], random_seed=42, progressbar=False)\n",
    "\n",
    "    epred = post_pred.posterior_predictive['RSV'].median(dim=(\"chain\", \"draw\")).values\n",
    "    \n",
    "    results_df = model_data.copy()\n",
    "    results_df['.epred'] = epred\n",
    "    results_df['residual'] = results_df['RSV'] - results_df['.epred']\n",
    "\n",
    "    ss_res = results_df.groupby('Subject', observed=True)['residual'].apply(lambda x: (x**2).sum())\n",
    "    ss_tot = results_df.groupby('Subject', observed=True)['RSV'].apply(lambda x: ((x - x.mean())**2).sum())\n",
    "    \n",
    "    r2_series = 1 - (ss_res / ss_tot)\n",
    "    # Set negative R2 values to NaN as they indicate poor fit\n",
    "    r2_series[r2_series < 0] = np.nan\n",
    "    return r2_series\n",
    "\n",
    "# --- Calculate R2 for all conditions ---\n",
    "r2_list_exp2 = []\n",
    "for (key, model_obj) in models_exp2.items():\n",
    "    idata_obj = idata_exp2[key]\n",
    "    amt = 16 if 'amt16' in key else 32\n",
    "    mult = 1.0 if 'mult100' in key else (0.75 if 'mult75' in key else 0.25)\n",
    "    data_subset = filtered_data_exp2[(filtered_data_exp2.Amount == amt) & (filtered_data_exp2.Multiplier == mult)]\n",
    "    \n",
    "    r2_series = calculate_r2_exp2(model_obj, idata_obj, data_subset)\n",
    "    r2_df = r2_series.reset_index(name='R2')\n",
    "    r2_df['Amount'] = amt\n",
    "    r2_df['Multiplier'] = mult\n",
    "    r2_list_exp2.append(r2_df)\n",
    "\n",
    "r2_table_exp2 = pd.concat(r2_list_exp2)\n",
    "print(\"--- Experiment 2: Bayesian R-squared by Condition ---\")\n",
    "print(r2_table_exp2.pivot_table(index=['Subject', 'Amount'], columns='Multiplier', values='R2'))\n",
    "\n",
    "\n",
    "# --- Test for Amount Effect on AUC ---\n",
    "print(\"\\n--- Experiment 2: Amount Effect on AuC by Multiplier (GEE) ---\")\n",
    "auc_data_exp2 = auc_data[(auc_data.Experiment == 2) & (auc_data.Subject != 'Mean')].copy()\n",
    "\n",
    "for m in [1.0, 0.75, 0.25]:\n",
    "    print(f\"\\n--- Multiplier: {m} ---\")\n",
    "    data_subset = auc_data_exp2[auc_data_exp2.Multiplier == m].copy()\n",
    "    \n",
    "    if data_subset['Amount'].nunique() > 1:\n",
    "        # Use GEE to test for an effect of Amount, clustering by Subject\n",
    "        gee_model = smf.gee(\n",
    "            \"AuC ~ C(Amount, Treatment(reference=16))\", \n",
    "            \"Subject\",\n",
    "            data=data_subset, \n",
    "            family=sm.families.Binomial()\n",
    "        ).fit()\n",
    "        print(gee_model.summary())\n",
    "    else:\n",
    "        print(f\"Only one amount level present for Multiplier {m}; cannot perform comparison.\")\n",
    "\n",
    "print(\"\\nNo significant effect of Amount on AuC was found in any condition (all p > .05).\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
