{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6f465c",
   "metadata": {},
   "source": [
    "# Discounting of Probabilistic Food Reinforcement by Pigeons\n",
    "\n",
    "This notebook replicates the analyses from the publication:\n",
    "\n",
    "> Oliveira, L., Green, L., Myerson, J., & Wan, H. (2025). Discounting of probabilistic food reinforcement by pigeons. *Journal of the Experimental Analysis of Behavior, 124*(1). https://doi.org/10.1002/jeab.70042\n",
    "\n",
    "The original R analysis is translated into a Python workflow using `pandas`, `pymc`, `arviz`, and `matplotlib`. The analysis uses Bayesian nonlinear multilevel models to fit a hyperboloid discounting function to pigeons' choices. **Experiment 1** examines choices between a certain and a probabilistic reward. **Experiment 2** extends this to choices between two probabilistic rewards.\n",
    "\n",
    "The data for this study are publicly available on the Open Science Framework at: <https://osf.io/scwg3/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5617ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy pymc arviz matplotlib seaborn scikit-learn openpyxl statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f990c31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: Imports and Custom Functions ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import auc as calculate_auc\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "def set_mattheme(ax, title=\"\"):\n",
    "    \"\"\"Applies a consistent plot theme.\"\"\"\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10, direction='out')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(1)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb0c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Processing ---\n",
    "# Load OSF Data\n",
    "rawdat_exp1 = pd.read_csv(\"r code/OSF/PigeonPD_Exp1.csv\")\n",
    "rawdat_exp2 = pd.read_csv(\"r code/OSF/PigeonPD_Exp2.csv\")\n",
    "\n",
    "# Process Experiment 1 Data\n",
    "disc_dat_exp1 = rawdat_exp1.copy()\n",
    "disc_dat_exp1['Experiment'] = 1\n",
    "disc_dat_exp1['Probability'] = disc_dat_exp1['Probability'].astype(str)\n",
    "disc_dat_exp1['Rep'] = disc_dat_exp1['Probability'].str.contains('R').astype(int)\n",
    "disc_dat_exp1['Prob'] = disc_dat_exp1['Probability'].str.replace('R', '').astype(float) / 100\n",
    "disc_dat_exp1['odds'] = (1 - disc_dat_exp1['Prob']) / disc_dat_exp1['Prob']\n",
    "disc_dat_exp1['rsv'] = disc_dat_exp1['SV'] / disc_dat_exp1['Amount']\n",
    "disc_dat_exp1['Multiplier'] = 1.0\n",
    "disc_dat_exp1['odds_m'] = 0\n",
    "\n",
    "# Process Experiment 2 Data\n",
    "disc_dat_exp2 = rawdat_exp2.copy()\n",
    "disc_dat_exp2['Experiment'] = 2\n",
    "disc_dat_exp2['Multiplier'] = disc_dat_exp2['Multiplier'].astype(str)\n",
    "disc_dat_exp2['Rep'] = disc_dat_exp2['Multiplier'].str.contains('R').astype(int)\n",
    "disc_dat_exp2['Multiplier'] = disc_dat_exp2['Multiplier'].str.replace('R', '').astype(float)\n",
    "disc_dat_exp2['Prob_Lg'] = disc_dat_exp2['Probability_Lg'] / 100\n",
    "disc_dat_exp2['Prob_Sm'] = disc_dat_exp2['Probability_Sm'] / 100\n",
    "disc_dat_exp2['odds'] = (1 - disc_dat_exp2['Prob_Lg']) / disc_dat_exp2['Prob_Lg']\n",
    "disc_dat_exp2['odds_m'] = (1 - disc_dat_exp2['Prob_Sm']) / disc_dat_exp2['Prob_Sm']\n",
    "disc_dat_exp2['rsv'] = disc_dat_exp2['SV'] / disc_dat_exp2['Amount']\n",
    "disc_dat_exp2.rename(columns={'Prob_Lg': 'Prob'}, inplace=True)\n",
    "\n",
    "# Combine Data and Create Mean Subject\n",
    "# CORRECTED: Added 'Subject' to the list of columns to keep.\n",
    "cols = ['Subject', 'Experiment', 'Multiplier', 'Amount', 'Rep', 'odds', 'rsv', 'odds_m', 'Prob']\n",
    "disc_dat = pd.concat([disc_dat_exp1[cols], disc_dat_exp2[cols]])\n",
    "\n",
    "disc_mean = disc_dat[disc_dat['Rep'] == 0].groupby(\n",
    "    ['Experiment', 'Amount', 'Multiplier', 'odds', 'Prob', 'odds_m']\n",
    ").agg(rsv=('rsv', 'mean')).reset_index()\n",
    "disc_mean['Subject'] = \"Mean\"\n",
    "disc_mean['Rep'] = 0\n",
    "\n",
    "disc_dat = pd.concat([disc_dat, disc_mean])\n",
    "subject_levels = [\"P41\",\"P42\",\"P43\",\"P44\",\"P45\",\"P46\",\"P47\",\"P48\",\"Mean\"]\n",
    "disc_dat['Subject'] = pd.Categorical(disc_dat['Subject'], categories=subject_levels, ordered=True)\n",
    "\n",
    "# Create AUC data\n",
    "auc_dat = disc_dat[disc_dat['Rep'] == 0].sort_values('odds').groupby(\n",
    "    ['Subject', 'Experiment', 'Multiplier', 'Amount']\n",
    ").apply(\n",
    "    lambda g: calculate_auc(g['odds'] / g['odds'].max(), g['rsv'])\n",
    ").reset_index(name='auc')\n",
    "\n",
    "print(\"Data processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470076b",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Certain vs. Probabilistic Rewards\n",
    "\n",
    "In Experiment 1, pigeons chose between a smaller, certain reinforcer and a larger, probabilistic reinforcer. The following section fits a hyperboloid discounting model to the data for each amount (16 and 32 pellets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [h, s, nu]\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 1: Bayesian Model Fitting ---\n",
    "def fit_exp1_model(data_filter):\n",
    "    coords = {\"Subject\": data_filter['Subject'].cat.categories}\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # Data\n",
    "        subject_idx = pd.Categorical(data_filter['Subject'], categories=coords[\"Subject\"]).codes\n",
    "        odds_data = pm.Data(\"odds_data\", data_filter['odds'].values)\n",
    "        \n",
    "        # Priors\n",
    "        h = pm.TruncatedNormal(\"h\", mu=1, sigma=10, lower=0, dims=\"Subject\")\n",
    "        s = pm.TruncatedNormal(\"s\", mu=1, sigma=10, lower=0, dims=\"Subject\")\n",
    "        nu = pm.HalfCauchy(\"nu\", beta=10, dims=\"Subject\")\n",
    "\n",
    "        # CORRECTED: Define the model on the logit scale, matching the brms formula\n",
    "        p = 1 / (1 + h[subject_idx] * odds_data)**s[subject_idx]\n",
    "        # eta is the linear predictor on the logit scale\n",
    "        eta = pm.math.log(p / (1 - p))\n",
    "        # mu is the mean, which is the inverse-logit of eta\n",
    "        mu = pm.math.invlogit(eta)\n",
    "        \n",
    "        # Likelihood\n",
    "        pm.Beta(\"rsv\", mu=mu, nu=nu[subject_idx], observed=data_filter['rsv'].values)\n",
    "        \n",
    "        # Sampling\n",
    "        idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, random_seed=42,\n",
    "                          progressbar=False, target_accept=0.95)\n",
    "    return idata\n",
    "\n",
    "# Fit models for both amounts\n",
    "idata_exp1_16 = fit_exp1_model(disc_dat[(disc_dat.Experiment == 1) & (disc_dat.Rep == 0) & (disc_dat.Amount == 16)])\n",
    "idata_exp1_32 = fit_exp1_model(disc_dat[(disc_dat.Experiment == 1) & (disc_dat.Rep == 0) & (disc_dat.Amount == 32)])\n",
    "\n",
    "print(\"Experiment 1 model fitting complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
